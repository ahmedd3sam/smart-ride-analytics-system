[2025-11-27T10:25:24.723+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: taxi_streaming_pipeline.run_flink_job manual__2025-11-27T10:24:14.396749+00:00 [queued]>
[2025-11-27T10:25:24.741+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: taxi_streaming_pipeline.run_flink_job manual__2025-11-27T10:24:14.396749+00:00 [queued]>
[2025-11-27T10:25:24.741+0000] {taskinstance.py:1359} INFO - Starting attempt 2 of 2
[2025-11-27T10:25:24.761+0000] {taskinstance.py:1380} INFO - Executing <Task(BashOperator): run_flink_job> on 2025-11-27 10:24:14.396749+00:00
[2025-11-27T10:25:24.768+0000] {standard_task_runner.py:57} INFO - Started process 265 to run task
[2025-11-27T10:25:24.779+0000] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'taxi_streaming_pipeline', 'run_flink_job', 'manual__2025-11-27T10:24:14.396749+00:00', '--job-id', '153', '--raw', '--subdir', 'DAGS_FOLDER/taxi_pipeline_dag.py', '--cfg-path', '/tmp/tmp9e4x7syj']
[2025-11-27T10:25:24.785+0000] {standard_task_runner.py:85} INFO - Job 153: Subtask run_flink_job
[2025-11-27T10:25:24.950+0000] {task_command.py:415} INFO - Running <TaskInstance: taxi_streaming_pipeline.run_flink_job manual__2025-11-27T10:24:14.396749+00:00 [running]> on host 485e0d4eae03
[2025-11-27T10:25:25.094+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Menna' AIRFLOW_CTX_DAG_ID='taxi_streaming_pipeline' AIRFLOW_CTX_TASK_ID='run_flink_job' AIRFLOW_CTX_EXECUTION_DATE='2025-11-27T10:24:14.396749+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-11-27T10:24:14.396749+00:00'
[2025-11-27T10:25:25.095+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-11-27T10:25:25.096+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', '\n        echo "=========================================="\n        echo "Submitting Flink Job"\n        echo "=========================================="\n\n        # Check if Docker is available\n        if ! command -v docker &> /dev/null; then\n            echo "ERROR: Docker command not available"\n            exit 1\n        fi\n\n        JOB_MANAGER_NAME="flink-jobmanager"\n        TASK_MANAGER_NAME="flink-taskmanager"\n        \n        # Verify JobManager is running\n        if ! docker ps --filter "name=^${JOB_MANAGER_NAME}$" -q | grep -q .; then\n            echo "ERROR: Flink JobManager container not running"\n            docker ps || true\n            exit 1\n        fi\n\n        # Verify TaskManager is running and ready\n        echo "Checking Flink TaskManager availability..."\n        if ! docker ps --filter "name=^${TASK_MANAGER_NAME}$" -q | grep -q .; then\n            echo "ERROR: Flink TaskManager container not running"\n            docker ps || true\n            exit 1\n        fi\n\n        echo "✓ Flink JobManager is running"\n        echo "✓ Flink TaskManager is running"\n\n        # Wait for Flink cluster to be fully ready\n        echo "Waiting for Flink cluster to be ready..."\n        MAX_RETRIES=30\n        RETRY_COUNT=0\n        FLINK_READY=0\n\n        while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do\n            # Check if Flink REST API is accessible\n            if docker exec "$JOB_MANAGER_NAME" curl -s http://localhost:8081/overview > /dev/null 2>&1; then\n                # Check if TaskManager is registered\n                TASK_MANAGERS=$(docker exec "$JOB_MANAGER_NAME" curl -s http://localhost:8081/taskmanagers 2>/dev/null | grep -o "taskmanagers" | wc -l || echo "0")\n                if [ "$TASK_MANAGERS" -gt "0" ]; then\n                    echo "✓ Flink cluster is ready (TaskManagers registered)"\n                    FLINK_READY=1\n                    break\n                fi\n            fi\n            RETRY_COUNT=$((RETRY_COUNT + 1))\n            echo "Waiting for Flink cluster... ($RETRY_COUNT/$MAX_RETRIES)"\n            sleep 2\n        done\n\n        if [ "$FLINK_READY" != "1" ]; then\n            echo "ERROR: Flink cluster not ready after $MAX_RETRIES retries"\n            echo "JobManager logs:"\n            docker logs "$JOB_MANAGER_NAME" 2>&1 | tail -20\n            exit 1\n        fi\n\n        # Wait a bit more for Kafka messages to be available\n        echo "Waiting for Kafka messages to be available..."\n        sleep 10\n\n        JOB_FILE="/opt/flink/jobs/kafka_consumer_ui.py"\n        echo "Verifying Flink job file: $JOB_FILE"\n        if ! docker exec "$JOB_MANAGER_NAME" test -f "$JOB_FILE"; then\n            echo "ERROR: Flink job file not found: $JOB_FILE"\n            echo "Files in /opt/flink/jobs:"\n            docker exec "$JOB_MANAGER_NAME" ls -la /opt/flink/jobs/ || true\n            exit 1\n        fi\n\n        # Verify the job file structure\n        echo "Verifying Flink job file structure..."\n        \n        # Check for env.execute()\n        if docker exec "$JOB_MANAGER_NAME" grep -q "^env.execute" "$JOB_FILE"; then\n            echo "✓ env.execute() is present"\n        else\n            echo "WARNING: env.execute() not found, attempting to uncomment..."\n            docker exec "$JOB_MANAGER_NAME" sed -i \'s/^# env.execute/env.execute/\' "$JOB_FILE" 2>/dev/null || true\n        fi\n        \n        # Check for INSERT INTO statement (creates the operator)\n        if docker exec "$JOB_MANAGER_NAME" grep -q "INSERT INTO" "$JOB_FILE"; then\n            echo "✓ INSERT INTO statement found (creates operator)"\n        else\n            echo "ERROR: INSERT INTO statement not found in job file!"\n            echo "The Flink job must have an INSERT INTO statement to create operators."\n            exit 1\n        fi\n        \n        # Check for source table definition\n        if docker exec "$JOB_MANAGER_NAME" grep -q "CREATE TABLE.*taxi_trips" "$JOB_FILE"; then\n            echo "✓ Source table definition found"\n        else\n            echo "WARNING: Source table definition may be missing"\n        fi\n        \n        # Check for sink table definition\n        if docker exec "$JOB_MANAGER_NAME" grep -q "CREATE TABLE.*taxi_trips_dashboard" "$JOB_FILE"; then\n            echo "✓ Sink table definition found"\n        else\n            echo "WARNING: Sink table definition may be missing"\n        fi\n\n        echo ""\n        echo "Submitting Flink job..."\n        echo "Command: flink run -py $JOB_FILE -d"\n        \n        # Submit the job\n        if docker exec "$JOB_MANAGER_NAME" flink run -py "$JOB_FILE" -d; then\n            echo ""\n            echo "✓ Flink job submitted successfully!"\n            echo "Job is running and will:"\n            echo "  - Consume from Kafka topic: s3-taxi-trips"\n            echo "  - Transform and enrich the data"\n            echo "  - Load into PostgreSQL table: taxi_trips_dashboard"\n            echo ""\n            echo "Check Flink UI at http://localhost:8081 for job status"\n        else\n            EXIT_CODE=$?\n            echo ""\n            echo "ERROR: Flink job submission failed (exit code: $EXIT_CODE)"\n            echo ""\n            echo "Flink JobManager logs (last 50 lines):"\n            echo "----------------------------------------"\n            docker logs "$JOB_MANAGER_NAME" 2>&1 | tail -50\n            echo "----------------------------------------"\n            echo ""\n            echo "Flink TaskManager logs (last 30 lines):"\n            echo "----------------------------------------"\n            docker logs "$TASK_MANAGER_NAME" 2>&1 | tail -30\n            echo "----------------------------------------"\n            echo ""\n            echo "Troubleshooting:"\n            echo "1. Check if Kafka has messages: docker exec kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic s3-taxi-trips --from-beginning --max-messages 1"\n            echo "2. Check Flink UI: http://localhost:8081"\n            echo "3. Verify connectors are available in /opt/flink/usrlib/"\n            exit $EXIT_CODE\n        fi\n        ']
[2025-11-27T10:25:25.108+0000] {subprocess.py:86} INFO - Output:
[2025-11-27T10:25:25.110+0000] {subprocess.py:93} INFO - ==========================================
[2025-11-27T10:25:25.110+0000] {subprocess.py:93} INFO - Submitting Flink Job
[2025-11-27T10:25:25.111+0000] {subprocess.py:93} INFO - ==========================================
[2025-11-27T10:25:25.283+0000] {subprocess.py:93} INFO - Checking Flink TaskManager availability...
[2025-11-27T10:25:25.337+0000] {subprocess.py:93} INFO - ✓ Flink JobManager is running
[2025-11-27T10:25:25.337+0000] {subprocess.py:93} INFO - ✓ Flink TaskManager is running
[2025-11-27T10:25:25.337+0000] {subprocess.py:93} INFO - Waiting for Flink cluster to be ready...
[2025-11-27T10:25:25.708+0000] {subprocess.py:93} INFO - ✓ Flink cluster is ready (TaskManagers registered)
[2025-11-27T10:25:25.708+0000] {subprocess.py:93} INFO - Waiting for Kafka messages to be available...
[2025-11-27T10:25:35.711+0000] {subprocess.py:93} INFO - Verifying Flink job file: /opt/flink/jobs/kafka_consumer_ui.py
[2025-11-27T10:25:35.875+0000] {subprocess.py:93} INFO - Verifying Flink job file structure...
[2025-11-27T10:25:36.029+0000] {subprocess.py:93} INFO - ✓ env.execute() is present
[2025-11-27T10:25:36.206+0000] {subprocess.py:93} INFO - ✓ INSERT INTO statement found (creates operator)
[2025-11-27T10:25:36.338+0000] {subprocess.py:93} INFO - ✓ Source table definition found
[2025-11-27T10:25:36.454+0000] {subprocess.py:93} INFO - ✓ Sink table definition found
[2025-11-27T10:25:36.454+0000] {subprocess.py:93} INFO - 
[2025-11-27T10:25:36.455+0000] {subprocess.py:93} INFO - Submitting Flink job...
[2025-11-27T10:25:36.455+0000] {subprocess.py:93} INFO - Command: flink run -py /opt/flink/jobs/kafka_consumer_ui.py -d
[2025-11-27T10:25:44.642+0000] {subprocess.py:93} INFO - WARNING: An illegal reflective access operation has occurred
[2025-11-27T10:25:44.642+0000] {subprocess.py:93} INFO - WARNING: Illegal reflective access by org.apache.flink.api.java.ClosureCleaner (file:/opt/flink/lib/flink-dist-1.17.2.jar) to field java.lang.String.value
[2025-11-27T10:25:44.643+0000] {subprocess.py:93} INFO - WARNING: Please consider reporting this to the maintainers of org.apache.flink.api.java.ClosureCleaner
[2025-11-27T10:25:44.643+0000] {subprocess.py:93} INFO - WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
[2025-11-27T10:25:44.643+0000] {subprocess.py:93} INFO - WARNING: All illegal access operations will be denied in a future release
